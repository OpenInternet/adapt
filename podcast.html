---
layout: podcast
---

<section id="podcasts">
    <div class="container-fluid pb-5">
        <div class="container">
            <div class="card-content pod">
                <div class="row pb-5 justify-content-between align-items-start">

                    <div class="col-12">
                        <h2 class="podcast-subscribe text-uppercase mb-2">
                            Sponsored by
                        </h2>
                        <div class="card-small mb-5">
                            <div class="row justify-content-around align-items-center">
                                <div class="col-auto justify-content-center">
                                    <img src="{{ site.baseurl }}/assets/images/sponsors/heinrich-boll-stiftung.svg"
                                        alt="Heinrich Boll Stiftung" width="292px" height="64px">
                                </div>
                                <div class="col-auto justify-content-center">
                                    <img src="{{ site.baseurl }}/assets/images/sponsors/internews.svg" alt="Internews"
                                        width="200px" height="60px">
                                </div>
                            </div>
                        </div>
                    </div>

                    <div class="col-12">
                        <h2 class="podcast-subscribe text-uppercase mb-2">
                            Where to listen
                        </h2>
                        <div class="row mb-5">
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/anchor.png" alt="AnchorFM"
                                        width="32px" height="32px"></a>
                            </div>
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/spotify.png" alt="Spotify"
                                        width="32px" height="32px"></a>
                            </div>
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/google_podcast.png"
                                        alt="Google Podcasts" width="32px" height="32px"></a>
                            </div>
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/upsidefm.png" alt="UpsideFM"
                                        width="32px" height="32px"></a>
                            </div>
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/pocketcasts.png" alt="Pocket Casts"
                                        width="32px" height="32px"></a>
                            </div>
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/radiopublic.png" alt="Radio Public"
                                        width="32px" height="32px"></a>
                            </div>
                            <div class="col-auto mb-2">
                                <a href="#" target="_blank" rel="noopener noreferrer"><img
                                        src="{{ site.baseurl }}/assets/images/icons/rss.png" alt="RSS Feed" width="32px"
                                        height="32px"></a>
                            </div>
                        </div>
                    </div>
                    <article>
                        <div class="col-12">
                            <iframe
                                src="https://anchor.fm/privacyisglobal/embed/episodes/Facial-Recognition-in-Brazil-Automating-Oppression-e17bn59"
                                height="165px" width="100%" frameborder="0" scrolling="no"></iframe>
                            <hr class="separator">
                            <h3 class="podcast-details mb-4">Episode Details</h3>
                            <div class="row">
                                <div class="col-12 position-relative">
                                    <img class="podcast-cover"
                                        src="{{ site.baseurl }}/assets/images/episodes/episode_one_cover.svg"
                                        width:="100px" height="100px" alt="Episode 1 Cover">

                                    <p class="podcast-number mb-0">Episode 1</p>
                                </div>
                                <div class="col-12 col-lg-9">
                                    <h1 class="podcast-title">Facial Recognition in Brazil: Automating Oppression?
                                    </h1>
                                </div>

                                <div class="col-12 col-lg-3 d-flex align-items-top justify-content-end">
                                    <div class="dropdown me-2">
                                        <button class="share-button dropdown-toggle" type="button"
                                            id="dropdownMenuButton1" data-bs-toggle="dropdown" aria-expanded="false">
                                            Share
                                        </button>
                                        <ul class="dropdown-menu" aria-labelledby="dropdownMenuButton1">
                                            <li><a class="dropdown-item" href="#">Share</a></li>
                                        </ul>
                                    </div>
                                    <div class="dropdown">
                                        <button class="listen-button dropdown-toggle" type="button"
                                            id="dropdownMenuButton2" data-bs-toggle="dropdown" aria-expanded="false">
                                            Listen
                                        </button>
                                        <ul class="dropdown-menu" aria-labelledby="dropdownMenuButton2">
                                            <li><a class="dropdown-item" href="#">Spotify</a></li>
                                            <li><a class="dropdown-item" href="#">Apple Podcasts</a></li>
                                            <li><a class="dropdown-item" href="#">Google Podcasts</a></li>
                                        </ul>
                                    </div>
                                </div>

                                <p>Produced by Coding Rights for the series Privacy is Global</p>

                                <p>In many places around the world, facial recognition technologies are gradually
                                    being deployed in several moments of our lives: be it in surveillance cameras
                                    installed across the streets we normally walk around or when we need to
                                    authenticate our IDs to allow access to social services or to enter banks and
                                    other private services. But what happens when we use a binary algorithm to
                                    control and influence non-binary and very diverse lives and experiences? Who
                                    gets excluded? What historical oppressions are being exacerbated and automated?
                                </p>

                                <p>Vanessa Koetz and Bianca Kremer, both Coding Rights fellows on Data and
                                    Feminisms, talked to two Brazilian experts: Mariah Rafaela Silva, scholar and
                                    activist in transgender rights and to Pablo Nunes, black scholar and activist
                                    specialist in public security and racism. Through this podcast, we will discuss
                                    the risks of implementing this kind of tech without an informed public debate
                                    about potential consequences. We even spoke to an algorithm, Dona Algô (Misses
                                    Algô… short for algorithm)! Are you curious? Press play!</p>

                                <h2 class="podcast-section">Links in this Episode</h2>

                                <ul class="ps-5">
                                    <li><a href="https://www.youtube.com/watch?v=omP93gEuQfI" target="_blank"
                                            rel="noopener noreferrer">From Devices To Bodies</a></li>
                                    <li><a href="https://privacyinternational.org/news-analysis/4474/threats-usage-facial-recognition-technologies-authenticating-transgender"
                                            target="_blank" rel="noopener noreferrer">Threats in the usage of facial
                                            recognition
                                            technologies for authenticating transgender identities</a></li>
                                    <li><a href="https://opanoptico.com.br/" target="_blank"
                                            rel="noopener noreferrer">Panóptico: Monitor do Reconhecimento Facial no
                                            Brasil</a></li>
                                </ul>

                                <h2 class="podcast-section">Credits</h2>

                                <p>
                                    Research and Interviews: Bianca Kremer and Vanessa Koetz<br />
                                    Concept and script: Juliana Mastrascusa and Joana Varon<br />
                                    Interviews: Pablo Nunes and Mariah Rafaela Silva<br />
                                    Fictional Character: @Malfeitona<br />
                                    Editing & Mixing: Ergi Shkëlzeni<br />
                                    Visual Design: Ura Design<br />
                                    Executive Producers for Privacy is Global: Laura Schwartz-Henderson and Laura
                                    Vidal<br />
                                    Sponsored by Internews and <a href="https://us.boell.org/en/homepage"
                                        target="_blank" rel="noopener noreferrer">Heinrich-Böll-Stiftung Washington</a>
                                </p>

                                <div class="col-6">
                                    <button class="d-inline-block" type="button" data-bs-toggle="collapse"
                                        data-bs-target="#episode1transcript" aria-expanded="false"
                                        aria-controls="episode1transcript">
                                        Show transcript
                                    </button>
                                </div>

                                <div class="collapse" id="episode1transcript">
                                    <div class="transcript">
                                        <textarea readonly>
1. Intro

Laura Henderson:
Welcome to Privacy is Global, a podcast brought to you by Internews and Heinrich Böll Foundation. Through this podcast, we will look at what is happening in privacy and data protection debates all around the world.

Laura Vidal:
In each episode, we will convene discussions on the development of Privacy politics and policy in Africa, Latin America, Asia, and the Middle East. As part of this podcast, we will be talking to activists in countries around the world. So, hear the stories behind the fight for better and more protective data-privacy laws and policies.

Laura Henderson:
I’m Laura, Laura Schwartz-Henderson.

Laura Vidal:
And I’m also Laura, but I’m Laura Vidal.

Laura Henderson:
Welcome to the party!

Laura Vidal:
Ok, Laura, let’s start from scratch. What is Privacy for you?

Laura Henderson:
Privacy to me is being able to navigate my world and knowing I have some control over how I’m seen and perceived and over my own identity, I think.

Laura Vidal:
Well, I love that you say “I think”, because Privacy is a lot of things for a lot of people.

Laura Henderson:
Exactly! It’s also freedom. Freedom to navigate your own space and determine who you are, and not have the world determine who you are for you.

Laura Vidal:
I once heard something that I liked a lot and that’s: “Privacy is an enabling right. So, it might be a little bit abstract, it might be a little bit invisible, but Privacy is what lets you participate or not participate in your own terms and in your own ways in whatever is happening around you.”

Laura Henderson:
Yeah, and I also think, it’s so interlinked with your right to express yourself because if you feel like you have Privacy, you are less likely to self-moderate and you are more likely to navigate your world, searching online or saying something to your friend that’s authentically you, rather than worrying about where that information will go and what it means.

Laura Vidal:
The thing is that now that we are so dependent and so used to these new technologies, the question about Privacy has changed quite a bit. Like, Privacy today, I feel is not the same thing that it was 30 years ago.

Laura Henderson:
Absolutely! I mean, you can be sitting in your room alone and have lots of information being collected on you. They can know where you are and essentially what you’re doing, who you’re talking to, without having to go anywhere. And it’s easy for us to think it’s so small, like, every tiny piece of data doesn’t feel big. And it feels like a part of a big system that you can control and so, once it starts it’s hard to stop.

Laura Vidal:
That’s a good point. There’s another thing. We’re really used to hearing debates and conversations and initiatives around data privacy that come from the same places that have really good representation. So, we know a bit already about what’s going on in conversations about Privacy in the US, and also in Europe. And that’s really important, especially in the US since a lot of the technologies were created having these populations in mind but these technologies are being used in so many places by so many people and in so many different ways, which means that there are many conversations about privacy that we are not really hearing about.

Laura Henderson:
That’s exactly why we wanted to do the series. As everybody knows, there’s a GDPR in Europe, which is changing the way that a lot of people talk about privacy regulations. There are conversations about what a Federal Privacy Legislation could look like in the US and state legislation but there are a lot of things happening all over the world, as we all come to terms with this new technological and social way of living. And other stories that we need to hear from activists who are pushing for new laws and pushing for protection and trying to force us to think critically about how we give away our data and the relationships we have with technology.

Laura Vidal:
Yeah, absolutely! I also think that governments are very much talking to each other and taking notes in whatever they do. So, I’m thinking that activists and people that care about these issues should also talk to each other and inspire each other in what they are doing.

Laura Henderson:
Inspire each other but also really understand what is contextually specific. If we're just copying regulations and laws, there's a lot of differences in how governments operate and what people are capable of, and how things can be enforced. And so, it's important to learn from the challenges that other jurisdictions are having, as we learn and grow and all collectively figure out how to govern in this new world.

Laura Vidal:
Yeah. Why don't you tell us a bit more about where this idea came from?

Laura Henderson:
As part of our project that we're running at Internews called the ADAPT project, we're working with a number of organizations to think through what privacy advocacy looks like in each of these countries, knowing that a lot of people are starting at different points. Public awareness on these issues might be lower or higher in some places, there might already be legislation passed, and then the real challenge is figuring out how to enforce those regulations, how to make sure regulatory bodies are independent, how to make sure they're well funded, how to deal with the politics of privacy laws. And all of these things are constantly changing and evolving and policymakers need to play “catch up” pretty much all the time and the activists are there, at the forefront of all of this, and we really wanted to hear their stories and their successes and highlight the work that they're doing.

Laura Vidal:
So to our listeners: You'll be hearing from us, but we will be passing the mic to many amazing organizations around the world for each episode. You'll hear from activists and experts as they take us to explore specific issues or as they help us understand the context of a particular country. For this first episode, we're passing the mic to Coding Rights and we're going to Brazil. Yeah, you're going to have an amazing experience listening to our wonderfully innovative friends from Coding Rights talk about how data privacy impacts gender identity, how it impacts racial discrimination, and also the colonial history in Brazil and what that means for surveillance and privacy. They'll also show us what it would be like to talk to an algorithm and what the ideas behind algorithms mean for how they function and how it scales versus societies.

Laura Henderson:
I can't wait to hear all that. Let's go!

2. Head

Vanessa Koetz:
It is not very hard to imagine a reality where we use our faces as means of identification to enter a building or to guarantee a fair reduction on public transportation. Maybe this is already happening where you live.

Bianca Kremer:
Way beyond cute filters on social media or the unlocking function of mobile apps, the implementation of facial recognition technologies is permeated by important debates on gender, race, and territory. I am Bianca Kremer, Data and Feminism fellow at Coding Rights.

Vanessa Koetz:
From devices to bodies, in this episode, we will talk about facial recognition, and the dangers of applying this tech, under narratives of public security, or for authenticating identities, particularly of people who do not fit in a privileged, white, cis, hetero, normative profile. I am Vanessa Koetz, also a Data and Feminism fellow at Coding Rights. Oh, and don't worry if you don't know much about facial recognition. This episode is full of daily life examples and we will also explain some key concepts about it.

Bianca Kremer:
If you have been following these debates for a while, take advantage of the next few minutes to get to know some very important research and productions that are being made here, in Brazil. The idea is to collectively advance in this debate. After all, it affects all of us as a society, doesn't it?

3. Miss Algô

In the Airport.

Another calm day of work from you Miss Algô, the airport assistance algorithm.
Nothing strange, nothing new. Let's go on to the next person.
“Male. White. Age: 20.”
Oh, what a nice young man.
“Single. French. Reason for travel: Study abroad.”
A dedicated student. This one may pass. Great profile to enter the country.
Next.
“Woman. White.”
Oh, I like her profile.
“Accountant. Age:30. German. Reason for travel: Business.”
Seems like a nice woman. Don't even need to ask anything. Let her in. Next.
“Male. Black.”
Wait, what? Who is this person? System, investigate him!
“Math teacher. Age: 35. Colombian.”
What is he trying to do here? Why is he threatening our borders?
“The reason for travel: Attending an academic event.”
Well, and who invited this guy over here?
“He was formally invited by the university.”
Oh, really? He still looks pretty suspicious to me. I can not let him thought
without the extra check. He needs to present proof of invitation and then maybe,
maybe I might allow him in.
“Well done. This is Algô. Another day keeping our borders secure.”
Oh, assistant. Thank you. You know, I'm just doing my job as I was programmed to
do.

4. Intro Pablo

Vanessa Koetz:
You have just listened to Miss Algô or, in Portuguese, Dona Algo, a fictional character that represents the algorithms of our everyday lives. She is our special guest for this episode.

Bianca Kremer:
Facial recognition technologies have proven to be powerful tools for mass surveillance that are being deployed under narratives about public security and innovation. But what are the consequences of deploying technologies that actually serve to reinforce discrimination against historically oppressed and persecuted populations?

Vanessa Koetz:
That is precisely why, in order to discuss facial recognition, we need to understand the contexts, in which this tech is being deployed, and the bodies, and territories, that are being targeted by it.

Bianca Kremer:
For instance, in Brazil, we are the third country with the highest rate of incarceration in the world. Among more than 770 thousand people imprisoned in the country, approximately 67% are black and brown. That is to say that two out of every three people imprisoned in Brazil are black and brown people. A rate that expresses a context of historical exclusion, a result of colonial violence, which, unfortunately, is likely to be similar in several places around the world.

Vanessa Koetz:
In 2020 two thousand twenty, the unemployment rate, among the black population in Brazil, was 71% higher than the rate for the white population. Considering the intersectionality of identities, it is further estimated that unemployment could reach 40% in the LGBT+ community, and 70% in the trans population.

Bianca Kremer:
A lot of data, yeah, we know. We are just trying to highlight that it is in this unequal and oppressive context that facial recognition is becoming popular in Brazil. Particularly since 2018, these technologies began to be widely implemented for policing public spaces from several regions in Brazil, especially at large metropolises like São Paulo, Rio de Janeiro, and Salvador.

Vanessa Koetz:
In the northeastern Brazilian state of Bahia alone, the system flagged more than 200 suspects. And we already know that some people ended up at the police station by mistake. While the number of arrests is increasing, the amount of information about the application of these systems by governmental agencies decreases. And so, quietly, on the sly, the use of facial recognition for policing is being normalized. And even defended.

Bianca Kremer:
To talk about facial recognition and public security in Brazil, I interviewed Pablo Nunes, Ph.D. in Political Science and researcher on issues related to public security in Brazil for 13 years. Since 2018, he has been coordinating the Center for Security and Citizenship Studies (CESeC), where he develops research and activism on human rights, public security, policing and the fight against racism. He coordinates the Security Observatories Network, an initiative that brings together Observatories in five Brazilian states. He conducts research on media, violence, social media, and new technologies allied to policing. He is also the founder of Panopticon: a project within CESeC to monitor the adoption of facial recognition technology by public security institutions in Brazil.

5. Interview

Bianca Kremer:
Hi Pablo, thank you so much for joining us. You have an impressive
                                            </textarea>
                                    </div>
                                </div>

                            </div>
                        </div>
                    </article>
                </div>
            </div>
        </div>
    </div>
</section>